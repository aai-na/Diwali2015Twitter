{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#section 1.1 - twitter miner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "\n",
      "CONSUMER_KEY = '56kWfxP8WyApnJTNCtBJRuO3c'\n",
      "CONSUMER_SECRET ='c87iGmGG9gogP770Kuscpzx7Bskh5HDdeJBwEjEJyiAj9Niw7I'\n",
      "OAUTH_TOKEN = '3497065692-7ZCJTWESEZG1l1LzQtSsEO1k15qtbp3rqNgQuNW'\n",
      "OAUTH_TOKEN_SECRET = 'RGAh7nOSYjMtIG1p6g9XfhaQomScnfD3LGtJ6cFFluZS1'\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "# Nothing to see by displaying twitter_api except that it's now a\n",
      "# defined variable\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<twitter.api.Twitter object at 0x11878310>\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import unquote to prevent url encoding errors in next_results\n",
      "from urllib import unquote\n",
      "\n",
      "# XXX: Set this variable to a trending topic, \n",
      "# or anything else for that matter. The example query below\n",
      "# was a trending topic when this content was being developed\n",
      "# and is used throughout the remainder of this chapter.\n",
      "\n",
      "q = '#Diwali' \n",
      "\n",
      "count = 100\n",
      "\n",
      "since = ''\n",
      "\n",
      "# use since_id to collect subsequent tweets \n",
      "# and prevent duplicate tweet collection\n",
      "since = 671503711135391745\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "\n",
      "search_results = twitter_api.search.tweets(q=q, count=count, since_id=since, until=since)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "\n",
      "# Iterate through 5 more batches of results by following the cursor\n",
      "\n",
      "for _ in range(100):\n",
      "    print \"Length of statuses\", len(statuses)\n",
      "    try:\n",
      "        next_results = search_results['search_metadata']['next_results']\n",
      "    except KeyError, e: # No more results when next_results doesn't exist\n",
      "        break\n",
      "        \n",
      "    # Create a dictionary from next_results, which has the following form:\n",
      "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
      "    kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
      "    \n",
      "    search_results = twitter_api.search.tweets(**kwargs)\n",
      "    statuses += search_results['statuses']\n",
      "\n",
      "# Show one sample search result by slicing the list...print json.dumps(statuses[0][\"id\"], indent=1)\n",
      "print json.dumps(statuses[0][\"id\"], indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length of statuses 0\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-71-ae8cabed295c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Show one sample search result by slicing the list...print json.dumps(statuses[0][\"id\"], indent=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "search_results = {u'search_metadata': {u'count': 3, u'completed_in': 0.018, u'max_id_str': u'659098331109396480', u'since_id_str': u'0', u'next_results': u'?max_id=658988574822432768&q=%23pycon&count=3&include_entities=1', u'refresh_url': u'?since_id=659098331109396480&q=%23pycon&include_entities=1', u'since_id': 0, u'query': u'%23pycon', u'max_id': 659098331109396480}, u'statuses': [{u'contributors': None, u'truncated': False, u'text': u'#pycon talk video is out. Test driven infrastructure with #ansible\\nhttps://t.co/4IJMjnKK7d', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 659098331109396480, u'favorite_count': 0, u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [], u'hashtags': [{u'indices': [0, 6], u'text': u'pycon'}, {u'indices': [58, 66], u'text': u'ansible'}], u'urls': [{u'url': u'https://t.co/4IJMjnKK7d', u'indices': [67, 90], u'expanded_url': u'https://youtu.be/c21VnhhQYNQ', u'display_url': u'youtu.be/c21VnhhQYNQ'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 0, u'id_str': u'659098331109396480', u'favorited': False, u'user': {u'follow_request_sent': False, u'has_extended_profile': False, u'profile_use_background_image': True, u'default_profile_image': False, u'id': 108232420, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/378800000162322653/zqDn_8hn.png', u'verified': False, u'profile_text_color': u'B88D86', u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/659044863854317569/ptQXUtqL_normal.jpg', u'profile_sidebar_fill_color': u'E2C1A9', u'entities': {u'description': {u'urls': []}}, u'followers_count': 73, u'profile_sidebar_border_color': u'899892', u'id_str': u'108232420', u'profile_background_color': u'47022B', u'listed_count': 3, u'is_translation_enabled': False, u'utc_offset': 19800, u'statuses_count': 59, u'description': u'Fullstack developer, Part-time devops, Consultant, Twilight Hater, Couch potato geek, Papercut Survivor.', u'friends_count': 139, u'location': u'Bengaluru, Karnataka', u'profile_link_color': u'7F4759', u'profile_image_url': u'http://pbs.twimg.com/profile_images/659044863854317569/ptQXUtqL_normal.jpg', u'following': False, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/108232420/1445963625', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/378800000162322653/zqDn_8hn.png', u'screen_name': u'poojasalpekar', u'lang': u'en', u'profile_background_tile': False, u'favourites_count': 1, u'name': u'Pooja Salpekar', u'notifications': False, u'url': None, u'created_at': u'Mon Jan 25 08:10:50 +0000 2010', u'contributors_enabled': False, u'time_zone': u'Mumbai', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Tue Oct 27 20:04:22 +0000 2015', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}, {u'contributors': None, u'truncated': False, u'text': u'RT @nnja: My slide on the cost of tech debt has been retweeted 460+ times. Happy that my message resonated! #PyCon2015 #pycon http://t.co/n\\u2026', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 659001634782072832, u'favorite_count': 0, u'source': u'<a href=\"http://itunes.apple.com/us/app/twitter/id409789998?mt=12\" rel=\"nofollow\">Twitter for Mac</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [{u'id': 17513031, u'indices': [3, 8], u'id_str': u'17513031', u'screen_name': u'nnja', u'name': u'Nina Zakharenko'}], u'hashtags': [{u'indices': [108, 118], u'text': u'PyCon2015'}, {u'indices': [119, 125], u'text': u'pycon'}], u'urls': [], u'media': [{u'source_user_id': 17513031, u'source_status_id_str': u'587109598647037952', u'expanded_url': u'http://twitter.com/nnja/status/587109598647037952/photo/1', u'display_url': u'pic.twitter.com/ntpIzdeZX2', u'url': u'http://t.co/ntpIzdeZX2', u'media_url_https': u'https://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg', u'source_user_id_str': u'17513031', u'source_status_id': 587109598647037952, u'id_str': u'587109573389082624', u'sizes': {u'small': {u'h': 191, u'resize': u'fit', u'w': 340}, u'large': {u'h': 576, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 337, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [126, 140], u'type': u'photo', u'id': 587109573389082624, u'media_url': u'http://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 505, u'id_str': u'659001634782072832', u'favorited': False, u'retweeted_status': {u'contributors': None, u'truncated': False, u'text': u'My slide on the cost of tech debt has been retweeted 460+ times. Happy that my message resonated! #PyCon2015 #pycon http://t.co/ntpIzdeZX2', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 587109598647037952, u'favorite_count': 307, u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [], u'hashtags': [{u'indices': [98, 108], u'text': u'PyCon2015'}, {u'indices': [109, 115], u'text': u'pycon'}], u'urls': [], u'media': [{u'expanded_url': u'http://twitter.com/nnja/status/587109598647037952/photo/1', u'display_url': u'pic.twitter.com/ntpIzdeZX2', u'url': u'http://t.co/ntpIzdeZX2', u'media_url_https': u'https://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg', u'id_str': u'587109573389082624', u'sizes': {u'small': {u'h': 191, u'resize': u'fit', u'w': 340}, u'large': {u'h': 576, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 337, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [116, 138], u'type': u'photo', u'id': 587109573389082624, u'media_url': u'http://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 505, u'id_str': u'587109598647037952', u'favorited': False, u'user': {u'follow_request_sent': False, u'has_extended_profile': False, u'profile_use_background_image': True, u'default_profile_image': False, u'id': 17513031, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/378800000176338076/zmb2BIpa.jpeg', u'verified': False, u'profile_text_color': u'EB9184', u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/656276737467150336/VfrzRrEY_normal.jpg', u'profile_sidebar_fill_color': u'F0B69A', u'entities': {u'description': {u'urls': []}}, u'followers_count': 2039, u'profile_sidebar_border_color': u'D8C9A3', u'id_str': u'17513031', u'profile_background_color': u'211A2D', u'listed_count': 93, u'is_translation_enabled': False, u'utc_offset': -14400, u'statuses_count': 2150, u'description': u'I write code. Python / JS / Java Developer. Born in Ukraine, raised in Brooklyn. I snowboard & ski. @recursecenter alum.  \\u0ca0_\\u0ca0', u'friends_count': 719, u'location': u'Cottonwood Heights, UT', u'profile_link_color': u'000000', u'profile_image_url': u'http://pbs.twimg.com/profile_images/656276737467150336/VfrzRrEY_normal.jpg', u'following': False, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/17513031/1443661158', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/378800000176338076/zmb2BIpa.jpeg', u'screen_name': u'nnja', u'lang': u'en', u'profile_background_tile': False, u'favourites_count': 1385, u'name': u'Nina Zakharenko', u'notifications': False, u'url': None, u'created_at': u'Thu Nov 20 15:18:15 +0000 2008', u'contributors_enabled': False, u'time_zone': u'Eastern Time (US & Canada)', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Sun Apr 12 04:26:50 +0000 2015', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}, u'user': {u'follow_request_sent': False, u'has_extended_profile': False, u'profile_use_background_image': True, u'default_profile_image': True, u'id': 311128212, u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme1/bg.png', u'verified': False, u'profile_text_color': u'333333', u'profile_image_url_https': u'https://abs.twimg.com/sticky/default_profile_images/default_profile_3_normal.png', u'profile_sidebar_fill_color': u'DDEEF6', u'entities': {u'description': {u'urls': []}}, u'followers_count': 36, u'profile_sidebar_border_color': u'C0DEED', u'id_str': u'311128212', u'profile_background_color': u'C0DEED', u'listed_count': 10, u'is_translation_enabled': False, u'utc_offset': -18000, u'statuses_count': 608, u'description': u'iOS practicioner, Zend/PHP5 Certified, husband of a teacher and father of two grown daughters.  Erstwhile musician and amateur chef', u'friends_count': 134, u'location': u'Tampa', u'profile_link_color': u'0084B4', u'profile_image_url': u'http://abs.twimg.com/sticky/default_profile_images/default_profile_3_normal.png', u'following': False, u'geo_enabled': False, u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme1/bg.png', u'screen_name': u'sciprojguy', u'lang': u'en', u'profile_background_tile': False, u'favourites_count': 794, u'name': u'Chris Woodard', u'notifications': False, u'url': None, u'created_at': u'Sat Jun 04 23:10:51 +0000 2011', u'contributors_enabled': False, u'time_zone': u'Quito', u'protected': False, u'default_profile': True, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Tue Oct 27 13:40:08 +0000 2015', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}, {u'contributors': None, u'truncated': False, u'text': u'RT @nnja: My slide on the cost of tech debt has been retweeted 460+ times. Happy that my message resonated! #PyCon2015 #pycon http://t.co/n\\u2026', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 658988574822432769, u'favorite_count': 0, u'source': u'<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for i\\u039fS</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [{u'id': 17513031, u'indices': [3, 8], u'id_str': u'17513031', u'screen_name': u'nnja', u'name': u'Nina Zakharenko'}], u'hashtags': [{u'indices': [108, 118], u'text': u'PyCon2015'}, {u'indices': [119, 125], u'text': u'pycon'}], u'urls': [], u'media': [{u'source_user_id': 17513031, u'source_status_id_str': u'587109598647037952', u'expanded_url': u'http://twitter.com/nnja/status/587109598647037952/photo/1', u'display_url': u'pic.twitter.com/ntpIzdeZX2', u'url': u'http://t.co/ntpIzdeZX2', u'media_url_https': u'https://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg', u'source_user_id_str': u'17513031', u'source_status_id': 587109598647037952, u'id_str': u'587109573389082624', u'sizes': {u'small': {u'h': 191, u'resize': u'fit', u'w': 340}, u'large': {u'h': 576, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 337, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [126, 140], u'type': u'photo', u'id': 587109573389082624, u'media_url': u'http://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 505, u'id_str': u'658988574822432769', u'favorited': False, u'retweeted_status': {u'contributors': None, u'truncated': False, u'text': u'My slide on the cost of tech debt has been retweeted 460+ times. Happy that my message resonated! #PyCon2015 #pycon http://t.co/ntpIzdeZX2', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 587109598647037952, u'favorite_count': 307, u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'symbols': [], u'user_mentions': [], u'hashtags': [{u'indices': [98, 108], u'text': u'PyCon2015'}, {u'indices': [109, 115], u'text': u'pycon'}], u'urls': [], u'media': [{u'expanded_url': u'http://twitter.com/nnja/status/587109598647037952/photo/1', u'display_url': u'pic.twitter.com/ntpIzdeZX2', u'url': u'http://t.co/ntpIzdeZX2', u'media_url_https': u'https://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg', u'id_str': u'587109573389082624', u'sizes': {u'small': {u'h': 191, u'resize': u'fit', u'w': 340}, u'large': {u'h': 576, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 337, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [116, 138], u'type': u'photo', u'id': 587109573389082624, u'media_url': u'http://pbs.twimg.com/media/CCXVC94WYAAff1r.jpg'}]}, u'in_reply_to_screen_name': None, u'in_reply_to_user_id': None, u'retweet_count': 505, u'id_str': u'587109598647037952', u'favorited': False, u'user': {u'follow_request_sent': False, u'has_extended_profile': False, u'profile_use_background_image': True, u'default_profile_image': False, u'id': 17513031, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/378800000176338076/zmb2BIpa.jpeg', u'verified': False, u'profile_text_color': u'EB9184', u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/656276737467150336/VfrzRrEY_normal.jpg', u'profile_sidebar_fill_color': u'F0B69A', u'entities': {u'description': {u'urls': []}}, u'followers_count': 2039, u'profile_sidebar_border_color': u'D8C9A3', u'id_str': u'17513031', u'profile_background_color': u'211A2D', u'listed_count': 93, u'is_translation_enabled': False, u'utc_offset': -14400, u'statuses_count': 2150, u'description': u'I write code. Python / JS / Java Developer. Born in Ukraine, raised in Brooklyn. I snowboard & ski. @recursecenter alum.  \\u0ca0_\\u0ca0', u'friends_count': 719, u'location': u'Cottonwood Heights, UT', u'profile_link_color': u'000000', u'profile_image_url': u'http://pbs.twimg.com/profile_images/656276737467150336/VfrzRrEY_normal.jpg', u'following': False, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/17513031/1443661158', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/378800000176338076/zmb2BIpa.jpeg', u'screen_name': u'nnja', u'lang': u'en', u'profile_background_tile': False, u'favourites_count': 1385, u'name': u'Nina Zakharenko', u'notifications': False, u'url': None, u'created_at': u'Thu Nov 20 15:18:15 +0000 2008', u'contributors_enabled': False, u'time_zone': u'Eastern Time (US & Canada)', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Sun Apr 12 04:26:50 +0000 2015', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}, u'user': {u'follow_request_sent': False, u'has_extended_profile': False, u'profile_use_background_image': True, u'default_profile_image': False, u'id': 15863810, u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme1/bg.png', u'verified': False, u'profile_text_color': u'333333', u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/3615012947/8da521a08b59514bddb277f1b6bbc142_normal.jpeg', u'profile_sidebar_fill_color': u'DDEEF6', u'entities': {u'url': {u'urls': [{u'url': u'https://t.co/tebjfmY1JL', u'indices': [0, 23], u'expanded_url': u'http://blog.fdp.io', u'display_url': u'blog.fdp.io'}]}, u'description': {u'urls': []}}, u'followers_count': 125, u'profile_sidebar_border_color': u'C0DEED', u'id_str': u'15863810', u'profile_background_color': u'C0DEED', u'listed_count': 12, u'is_translation_enabled': False, u'utc_offset': -25200, u'statuses_count': 2459, u'description': u'iOS/Android Developer at Shiftboard, serial hobbyist, veteran, and polyglot.', u'friends_count': 339, u'location': u'Seattle, WA', u'profile_link_color': u'0084B4', u'profile_image_url': u'http://pbs.twimg.com/profile_images/3615012947/8da521a08b59514bddb277f1b6bbc142_normal.jpeg', u'following': False, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/15863810/1365961074', u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme1/bg.png', u'screen_name': u'nanoxd', u'lang': u'en', u'profile_background_tile': False, u'favourites_count': 50, u'name': u'Fernando Paredes', u'notifications': False, u'url': u'https://t.co/tebjfmY1JL', u'created_at': u'Fri Aug 15 15:17:43 +0000 2008', u'contributors_enabled': False, u'time_zone': u'Pacific Time (US & Canada)', u'protected': False, u'default_profile': True, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'en', u'created_at': u'Tue Oct 27 12:48:14 +0000 2015', u'in_reply_to_status_id_str': None, u'place': None, u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'}}]}\n",
      "\n",
      "filename = \"asiya-diwali_saved-tweets15.json\"\n",
      "\n",
      "# Save tweets to a file\n",
      "\n",
      "with open(filename, \"w\") as fp:\n",
      "    json.dump(statuses, fp)\n",
      "\n",
      "print \"tweets saved to file\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 759, in structured_traceback\n",
        "    records = _fixed_getinnerframes(etb, context, tb_offset)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 242, in _fixed_getinnerframes\n",
        "    records  = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
        "  File \"/usr/lib/python2.7/inspect.py\", line 1043, in getinnerframes\n",
        "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/lib/python2.7/inspect.py\", line 1003, in getframeinfo\n",
        "    filename = getsourcefile(frame) or getfile(frame)\n",
        "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
        "    if hasattr(getmodule(object, filename), '__loader__'):\n",
        "  File \"/usr/lib/python2.7/inspect.py\", line 491, in getmodule\n",
        "    if ismodule(module) and hasattr(module, '__file__'):\n",
        "KeyboardInterrupt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Internal Python error in the inspect module.\n",
        "Below is the traceback from this internal error.\n",
        "\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'statuses' is not defined",
       "output_type": "pyerr",
       "traceback": ""
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Unfortunately, your original traceback can not be constructed.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 2.1 - code to prep tweets for analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import json if not running above cells\n",
      "#open file for analysis\n",
      "#will be running single files instead of combining into one variable\n",
      "#only way to manage without crashing\n",
      "\n",
      "import json\n",
      "\n",
      "with open(\"asiya-diwali-saved_tweets3b.json\", \"r\") as fp:\n",
      "    batch= json.load(fp)\n",
      "    \n",
      "print \"batchdone\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "batchdone\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parse json for status texts 'only'\n",
      "#do this for all the tweets stored in variable batchx from above\n",
      "\n",
      "status_texts = [tweet['text']\n",
      "                for tweet in batch ]\n",
      "\n",
      "print \"tweets ready\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tweets ready\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save tweets to new file containing ONLY statuses\n",
      "# **DON'T FORGET TO RENAME USING 'a' AT THE END OF FILENAME\n",
      "# TO SHOW THAT THIS IS A STATUS_TEXT ONLY FILE**\n",
      "\n",
      "filename = \"asiya-diwali_saved-tweets16a.json\"\n",
      "\n",
      "# Save tweets to a file\n",
      "\n",
      "with open(filename, \"w\") as fp:\n",
      "    json.dump(status_texts, fp)\n",
      "\n",
      "print \"tweets saved to file\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tweets saved to file\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 2.2 - sentiment analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#store positive words in list\n",
      "#open file containing list of positive words\n",
      "#run ONCE\n",
      "\n",
      "positive_words = []\n",
      "\n",
      "with open (\"positive-words.txt\", \"r\") as fp:\n",
      "        for line in fp:\n",
      "            if line [0] != \";\":\n",
      "                positive_words.append(line.strip())\n",
      "                \n",
      "print \"positive words done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "positive words done\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#store negative words in list\n",
      "#open file containing list of negative words\n",
      "#run ONCE\n",
      "\n",
      "negative_words = []\n",
      "\n",
      "with open (\"negative-words.txt\", \"r\") as fp:\n",
      "        for line in fp:\n",
      "            if line [0] != \";\":\n",
      "                negative_words.append(line.strip())\n",
      "                \n",
      "print \"negative words done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "negative words done\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SENTIMENT ANALYSIS\n",
      "#use arrays to loop through words\n",
      "#count all words\n",
      "\n",
      "def split(arr, size):\n",
      "    arrs = []\n",
      "    while len(arr) > size:\n",
      "        pice = arr[:size]\n",
      "        arrs.append(pice)\n",
      "        arr = arr[:size]\n",
      "    arr.append(arr)\n",
      "    return arrs\n",
      "#print(split(status_texts, 1))\n",
      "\n",
      "all_words_in_diwali = [w\n",
      "    for status in status_texts\n",
      "    for w in status.split()]\n",
      "\n",
      "boo = 0\n",
      "\n",
      "for word in all_words_in_diwali:\n",
      "    if text != ',':\n",
      "        boo+=1\n",
      "print \"total words in this file is\" , boo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total words in this file is 79177\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count all positive words\n",
      "#create variable equal to zero for positive\n",
      "#if word is found in positive, add to positive count\n",
      "#count all negative words\n",
      "#create variable equal to zero for negative\n",
      "#if word is found in negative, add to negative count\n",
      "positive = 0\n",
      "negative = 0\n",
      "\n",
      "for word in all_words_in_diwali:\n",
      "    if word in all_words_in_diwali:\n",
      "        if word in positive_words:\n",
      "            positive += 1\n",
      "        elif word in negative_words:\n",
      "            negative += 1\n",
      "            \n",
      "print \"number of positive words:\" , positive\n",
      "print \"number of negative words:\" , negative\n",
      "\n",
      "if positive > negative:\n",
      "    print \"most of the tweets are positve!\"\n",
      "elif negative > positive:\n",
      "    print \"most of the tweets are negative.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of positive words: 1552\n",
        "number of negative words: 200\n",
        "most of the tweets are positve!\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:14: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 2.3 - analysing code for entities screenname and hashtag"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#to collect all screennames from each tweet\n",
      "\n",
      "screen_names = [ user_mention['screen_name'] \n",
      "                 for status in batch\n",
      "                     for user_mention in status['entities']['user_mentions'] ]\n",
      "\n",
      "#to collect all hashtags from each tweet\n",
      "\n",
      "hashtags = [ hashtag['text'] \n",
      "             for status in batch\n",
      "                 for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "\n",
      "# Compute a collection of all words from all tweets\n",
      "words = [ w \n",
      "          for t in status_texts \n",
      "              for w in t.split() ]\n",
      "\n",
      "#print the first five of each, screen_names, hashtags, words\n",
      "\n",
      "print json.dumps(screen_names[0:5], indent=1) \n",
      "print json.dumps(hashtags[0:5], indent=1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\n",
        " \"TeamTCS\", \n",
        " \"araijain\", \n",
        " \"araijain\", \n",
        " \"araijain\", \n",
        " \"araijain\"\n",
        "]\n",
        "[\n",
        " \"Diwali\", \n",
        " \"fun\", \n",
        " \"Vodafone\", \n",
        " \"Diwali\", \n",
        " \"selfie\"\n",
        "]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#to count the items, and find out which one is the most common\n",
      "#import the counter library into twitter miner\n",
      "\n",
      "from collections import Counter\n",
      "\n",
      "#count in screen_names and hashtags\n",
      "#print up until the top :10\n",
      "\n",
      "for item in [screen_names, hashtags]:\n",
      "    c = Counter(item)\n",
      "    print c.most_common()[:10] # top 10\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'araijain', 18), (u'bloggiri', 3), (u'indiblogger', 3), (u'blogadda', 3), (u'KhamariKruttika', 1), (u'echemistin', 1), (u'Boraie', 1), (u'SmithMBA', 1), (u'TeamTCS', 1)]\n",
        "\n",
        "[(u'Diwali', 21), (u'photoyatra', 18), (u'TheLifesWay', 18), (u'htconelifesa', 12), (u'pink', 6), (u'Diya', 6), (u'festival', 6), (u'htconem9', 6), (u'home', 6), (u'selfie', 6)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 2.4 - to sort by date"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "\n",
      "# created_at = 'Mon Jun 8 10:51:32 +0000 2009' # Get this string from the Twitter API\n",
      "created_at = batch[0][\"created_at\"]\n",
      "dt_obj = time.strptime(created_at, '%a %b %d %H:%M:%S +0000 %Y')\n",
      "\n",
      "print dt_obj\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "time.struct_time(tm_year=2015, tm_mon=12, tm_mday=3, tm_hour=3, tm_min=35, tm_sec=7, tm_wday=3, tm_yday=337, tm_isdst=-1)\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "day = str(dt_obj.tm_year) + \"_\" + str(dt_obj.tm_mon) + \"_\" +str(dt_obj.tm_mday)\n",
      "\n",
      "day_bucket = {}\n",
      "\n",
      "if day in day_bucket:\n",
      "    day_bucket[day] += 1\n",
      "else:\n",
      "    day_bucket[day] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from prettytable import PrettyTable\n",
      "\n",
      "pt = PrettyTable(field_names=['Date', 'Count'])\n",
      "\n",
      "for key in day_bucket:\n",
      "    row = [key, day_bucket[key]]\n",
      "    pt.add_row(row)\n",
      "    \n",
      "pt.align['Date'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+-----------+-------+\n",
        "| Date      | Count |\n",
        "+-----------+-------+\n",
        "| 2015_12_3 |     1 |\n",
        "+-----------+-------+\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "day_bucket = {}\n",
      "\n",
      "for tweet in batch:\n",
      "    created_at = tweet[\"created_at\"]\n",
      "    dt_obj = time.strptime(created_at, '%a %b %d %H:%M:%S +0000 %Y')\n",
      "    day = str(dt_obj.tm_year) + \"_\" + str(dt_obj.tm_mon) + \"_\" +str(dt_obj.tm_mday)\n",
      "    if day in day_bucket:\n",
      "        day_bucket[day] += 1\n",
      "    else:\n",
      "        day_bucket[day] = 1\n",
      "\n",
      "pt = PrettyTable(field_names=['Date', 'Count'])\n",
      "\n",
      "for key in day_bucket:\n",
      "    row = [key, day_bucket[key]]\n",
      "    pt.add_row(row)\n",
      "    \n",
      "pt.align['Date'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+------------+-------+\n",
        "| Date       | Count |\n",
        "+------------+-------+\n",
        "| 2015_11_28 |   180 |\n",
        "| 2015_11_29 |   206 |\n",
        "| 2015_11_24 |   236 |\n",
        "| 2015_11_25 |   447 |\n",
        "| 2015_11_26 |   500 |\n",
        "| 2015_11_30 |   190 |\n",
        "| 2015_12_2  |   180 |\n",
        "| 2015_12_3  |    11 |\n",
        "| 2015_12_1  |   391 |\n",
        "| 2015_11_27 |   449 |\n",
        "+------------+-------+\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 2.5 - random tweet selector\n",
      "I didn't end up using this.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "with open(\"asiya-diwali-saved_tweets4.json\", \"r\") as fp:\n",
      "    statuses= json.load(fp)\n",
      "    \n",
      "print \"batchdone\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "batchdone\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "status_texts = [ status['text'] \n",
      "                 for status in statuses ]\n",
      "\n",
      "for _ in range(5):\n",
      "    print json.dumps(random.choice(status_texts), indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"RT @bigbasket_com: This #Diwali Get 20% Cashback when you shop on bigbasket and pay with the @MobiKwik Diwali Mela! https://t.co/GRnyP29UeW\"\n",
        "\"RT @Jewels5_: Gift #Solitaires to your favorite on this #Diwali &amp; enjoy 25% off on all products \\nhttps://t.co/WeAZP0OxvM \\n\\n#DiamondWaliDiwa\\u2026\"\n",
        "\"\\\"@MikaSingh: Lukin fwd to a Dhamakedar show on 6th Nov #Bangalore #Diwali festivities @ book your tickets now!!! https://t.co/LXtlhXYMVP\\\"\"\n",
        "\"\\\"#Vedalam \\\" Today Official Paper Ad, WorldWide Releasing From #November_10th This #Diwali, #Coimbatore Theatre List https://t.co/OFpwSpfbgn\"\n",
        "\"Happy Diwali 2015 Wishes, Images, Messages https://t.co/nWxeUVEnoy #Diwali #Greetings #Quotes #Wishes\""
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# section 3.1 - other ideas\n",
      "As I was working on my analysis, I started to formulate other possible areas of exploration in relation to Diwali using the twitter API.\n",
      "Unfortunately, the mining and analysis process of the tweets I'd collected took a very long time, so in the end I couldn't actually do\n",
      "any further mining or analysis because I ran out of time.\n",
      "\n",
      "I thought I would try and create some code anyway, just out of curiousity and to see what I could come up with.\n",
      "\n",
      "Not all of this code works.  Some of it I was still working on when the assignment deadline approached."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# geolocation based query to look for tweets within a 10km radius Leicester city centre\n",
      "# this is because I wanted to know who is tweeting about Diwali in Leicestr\n",
      "\n",
      "from urllib import unquote\n",
      "\n",
      "# the hashtag 'Diwali' is unlikely to work anymore, this is just for demonstration purposes\n",
      "# to test that the location query works, I took out the Diwali query and ran it just to check\n",
      "# that it collects tweets from Leicester\n",
      "\n",
      "q = '#Diwali' \n",
      "\n",
      "count = 100\n",
      "\n",
      "since = ''\n",
      "\n",
      "search_results = twitter_api.search.tweets(geocode = \"52.6360565,-1.2011397,10km\", place_type = \"Leicester\", count=count, since_id=since)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "\n",
      "# Iterate through 5 more batches of results by following the cursor\n",
      "\n",
      "for _ in range(5):\n",
      "    print \"Length of statuses\", len(statuses)\n",
      "    try:\n",
      "        next_results = search_results['search_metadata']['next_results']\n",
      "    except KeyError, e: # No more results when next_results doesn't exist\n",
      "        break\n",
      "        \n",
      "    # Create a dictionary from next_results, which has the following form:\n",
      "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
      "    kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
      "    \n",
      "    search_results = twitter_api.search.tweets(**kwargs)\n",
      "    statuses += search_results['statuses']\n",
      "\n",
      "# Show one sample search result by slicing the list...\n",
      "print json.dumps(statuses[0][\"id\"], indent=1)\n",
      "\n",
      "# it worked!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length of statuses 100\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 293\n",
        "{\n",
        " \"contributors\": null, \n",
        " \"truncated\": false, \n",
        " \"text\": \"RT @CityofSanctuary: Birmingham declared City of Sanctuary for refugees today https://t.co/6FfiToVjWA\", \n",
        " \"is_quote_status\": false, \n",
        " \"in_reply_to_status_id\": null, \n",
        " \"id\": 672879283245854720, \n",
        " \"favorite_count\": 0, \n",
        " \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \n",
        " \"retweeted\": false, \n",
        " \"coordinates\": null, \n",
        " \"entities\": {\n",
        "  \"symbols\": [], \n",
        "  \"user_mentions\": [\n",
        "   {\n",
        "    \"id\": 106690828, \n",
        "    \"indices\": [\n",
        "     3, \n",
        "     19\n",
        "    ], \n",
        "    \"id_str\": \"106690828\", \n",
        "    \"screen_name\": \"CityofSanctuary\", \n",
        "    \"name\": \"City of Sanctuary\"\n",
        "   }\n",
        "  ], \n",
        "  \"hashtags\": [], \n",
        "  \"urls\": [\n",
        "   {\n",
        "    \"url\": \"https://t.co/6FfiToVjWA\", \n",
        "    \"indices\": [\n",
        "     78, \n",
        "     101\n",
        "    ], \n",
        "    \"expanded_url\": \"http://www.birminghammail.co.uk/news/midlands-news/birmingham-declared-city-sanctuary-refugees-10546203#ICID=sharebar_twitter\", \n",
        "    \"display_url\": \"birminghammail.co.uk/news/midlands-\\u2026\"\n",
        "   }\n",
        "  ]\n",
        " }, \n",
        " \"in_reply_to_screen_name\": null, \n",
        " \"in_reply_to_user_id\": null, \n",
        " \"retweet_count\": 7, \n",
        " \"id_str\": \"672879283245854720\", \n",
        " \"favorited\": false, \n",
        " \"retweeted_status\": {\n",
        "  \"contributors\": null, \n",
        "  \"truncated\": false, \n",
        "  \"text\": \"Birmingham declared City of Sanctuary for refugees today https://t.co/6FfiToVjWA\", \n",
        "  \"is_quote_status\": false, \n",
        "  \"in_reply_to_status_id\": null, \n",
        "  \"id\": 672853643763294209, \n",
        "  \"favorite_count\": 6, \n",
        "  \"source\": \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\", \n",
        "  \"retweeted\": false, \n",
        "  \"coordinates\": {\n",
        "   \"type\": \"Point\", \n",
        "   \"coordinates\": [\n",
        "    -1.1598926, \n",
        "    52.6282638\n",
        "   ]\n",
        "  }, \n",
        "  \"entities\": {\n",
        "   \"symbols\": [], \n",
        "   \"user_mentions\": [], \n",
        "   \"hashtags\": [], \n",
        "   \"urls\": [\n",
        "    {\n",
        "     \"url\": \"https://t.co/6FfiToVjWA\", \n",
        "     \"indices\": [\n",
        "      57, \n",
        "      80\n",
        "     ], \n",
        "     \"expanded_url\": \"http://www.birminghammail.co.uk/news/midlands-news/birmingham-declared-city-sanctuary-refugees-10546203#ICID=sharebar_twitter\", \n",
        "     \"display_url\": \"birminghammail.co.uk/news/midlands-\\u2026\"\n",
        "    }\n",
        "   ]\n",
        "  }, \n",
        "  \"in_reply_to_screen_name\": null, \n",
        "  \"in_reply_to_user_id\": null, \n",
        "  \"retweet_count\": 7, \n",
        "  \"id_str\": \"672853643763294209\", \n",
        "  \"favorited\": false, \n",
        "  \"user\": {\n",
        "   \"follow_request_sent\": false, \n",
        "   \"has_extended_profile\": false, \n",
        "   \"profile_use_background_image\": true, \n",
        "   \"default_profile_image\": false, \n",
        "   \"id\": 106690828, \n",
        "   \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "   \"verified\": false, \n",
        "   \"profile_text_color\": \"333333\", \n",
        "   \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/639442544271605762/pneWWLUQ_normal.png\", \n",
        "   \"profile_sidebar_fill_color\": \"DDEEF6\", \n",
        "   \"entities\": {\n",
        "    \"url\": {\n",
        "     \"urls\": [\n",
        "      {\n",
        "       \"url\": \"http://t.co/1IRDW77cSM\", \n",
        "       \"indices\": [\n",
        "        0, \n",
        "        22\n",
        "       ], \n",
        "       \"expanded_url\": \"http://www.cityofsanctuary.org\", \n",
        "       \"display_url\": \"cityofsanctuary.org\"\n",
        "      }\n",
        "     ]\n",
        "    }, \n",
        "    \"description\": {\n",
        "     \"urls\": []\n",
        "    }\n",
        "   }, \n",
        "   \"followers_count\": 2871, \n",
        "   \"profile_sidebar_border_color\": \"C0DEED\", \n",
        "   \"id_str\": \"106690828\", \n",
        "   \"profile_background_color\": \"C7C1EB\", \n",
        "   \"listed_count\": 85, \n",
        "   \"is_translation_enabled\": false, \n",
        "   \"utc_offset\": 3600, \n",
        "   \"statuses_count\": 2082, \n",
        "   \"description\": \"A movement to make the UK a place of welcome for people seeking Sanctuary.\", \n",
        "   \"friends_count\": 822, \n",
        "   \"location\": \"Across the UK\", \n",
        "   \"profile_link_color\": \"0084B4\", \n",
        "   \"profile_image_url\": \"http://pbs.twimg.com/profile_images/639442544271605762/pneWWLUQ_normal.png\", \n",
        "   \"following\": false, \n",
        "   \"geo_enabled\": true, \n",
        "   \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/106690828/1448880715\", \n",
        "   \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "   \"screen_name\": \"CityofSanctuary\", \n",
        "   \"lang\": \"en\", \n",
        "   \"profile_background_tile\": false, \n",
        "   \"favourites_count\": 422, \n",
        "   \"name\": \"City of Sanctuary\", \n",
        "   \"notifications\": false, \n",
        "   \"url\": \"http://t.co/1IRDW77cSM\", \n",
        "   \"created_at\": \"Wed Jan 20 10:35:41 +0000 2010\", \n",
        "   \"contributors_enabled\": false, \n",
        "   \"time_zone\": \"Amsterdam\", \n",
        "   \"protected\": false, \n",
        "   \"default_profile\": false, \n",
        "   \"is_translator\": false\n",
        "  }, \n",
        "  \"geo\": {\n",
        "   \"type\": \"Point\", \n",
        "   \"coordinates\": [\n",
        "    52.6282638, \n",
        "    -1.1598926\n",
        "   ]\n",
        "  }, \n",
        "  \"in_reply_to_user_id_str\": null, \n",
        "  \"possibly_sensitive\": false, \n",
        "  \"lang\": \"en\", \n",
        "  \"created_at\": \"Fri Dec 04 19:03:04 +0000 2015\", \n",
        "  \"in_reply_to_status_id_str\": null, \n",
        "  \"place\": {\n",
        "   \"full_name\": \"Leicester, England\", \n",
        "   \"url\": \"https://api.twitter.com/1.1/geo/id/38d67cacb385e69d.json\", \n",
        "   \"country\": \"United Kingdom\", \n",
        "   \"place_type\": \"city\", \n",
        "   \"bounding_box\": {\n",
        "    \"type\": \"Polygon\", \n",
        "    \"coordinates\": [\n",
        "     [\n",
        "      [\n",
        "       -1.215135, \n",
        "       52.580667\n",
        "      ], \n",
        "      [\n",
        "       -1.046205, \n",
        "       52.580667\n",
        "      ], \n",
        "      [\n",
        "       -1.046205, \n",
        "       52.67186\n",
        "      ], \n",
        "      [\n",
        "       -1.215135, \n",
        "       52.67186\n",
        "      ]\n",
        "     ]\n",
        "    ]\n",
        "   }, \n",
        "   \"contained_within\": [], \n",
        "   \"country_code\": \"GB\", \n",
        "   \"attributes\": {}, \n",
        "   \"id\": \"38d67cacb385e69d\", \n",
        "   \"name\": \"Leicester\"\n",
        "  }, \n",
        "  \"metadata\": {\n",
        "   \"iso_language_code\": \"en\", \n",
        "   \"result_type\": \"recent\"\n",
        "  }\n",
        " }, \n",
        " \"user\": {\n",
        "  \"follow_request_sent\": false, \n",
        "  \"has_extended_profile\": false, \n",
        "  \"profile_use_background_image\": true, \n",
        "  \"default_profile_image\": false, \n",
        "  \"id\": 1622910348, \n",
        "  \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "  \"verified\": false, \n",
        "  \"profile_text_color\": \"333333\", \n",
        "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/633382371933442048/v4dK6EYb_normal.jpg\", \n",
        "  \"profile_sidebar_fill_color\": \"DDEEF6\", \n",
        "  \"entities\": {\n",
        "   \"url\": {\n",
        "    \"urls\": [\n",
        "     {\n",
        "      \"url\": \"http://t.co/uXAy0RkCqp\", \n",
        "      \"indices\": [\n",
        "       0, \n",
        "       22\n",
        "      ], \n",
        "      \"expanded_url\": \"http://www.doctorsoftheworld.org.uk\", \n",
        "      \"display_url\": \"doctorsoftheworld.org.uk\"\n",
        "     }\n",
        "    ]\n",
        "   }, \n",
        "   \"description\": {\n",
        "    \"urls\": []\n",
        "   }\n",
        "  }, \n",
        "  \"followers_count\": 142, \n",
        "  \"profile_sidebar_border_color\": \"C0DEED\", \n",
        "  \"id_str\": \"1622910348\", \n",
        "  \"profile_background_color\": \"C0DEED\", \n",
        "  \"listed_count\": 3, \n",
        "  \"is_translation_enabled\": false, \n",
        "  \"utc_offset\": null, \n",
        "  \"statuses_count\": 369, \n",
        "  \"description\": \"Health manager, humanitarian. Views my own.\", \n",
        "  \"friends_count\": 369, \n",
        "  \"location\": \"London\", \n",
        "  \"profile_link_color\": \"0084B4\", \n",
        "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/633382371933442048/v4dK6EYb_normal.jpg\", \n",
        "  \"following\": false, \n",
        "  \"geo_enabled\": false, \n",
        "  \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \n",
        "  \"screen_name\": \"mslucyjones\", \n",
        "  \"lang\": \"en\", \n",
        "  \"profile_background_tile\": false, \n",
        "  \"favourites_count\": 11, \n",
        "  \"name\": \"Lucy Jones\", \n",
        "  \"notifications\": false, \n",
        "  \"url\": \"http://t.co/uXAy0RkCqp\", \n",
        "  \"created_at\": \"Fri Jul 26 13:17:08 +0000 2013\", \n",
        "  \"contributors_enabled\": false, \n",
        "  \"time_zone\": null, \n",
        "  \"protected\": false, \n",
        "  \"default_profile\": true, \n",
        "  \"is_translator\": false\n",
        " }, \n",
        " \"geo\": null, \n",
        " \"in_reply_to_user_id_str\": null, \n",
        " \"possibly_sensitive\": false, \n",
        " \"lang\": \"en\", \n",
        " \"created_at\": \"Fri Dec 04 20:44:57 +0000 2015\", \n",
        " \"in_reply_to_status_id_str\": null, \n",
        " \"place\": null, \n",
        " \"metadata\": {\n",
        "  \"iso_language_code\": \"en\", \n",
        "  \"result_type\": \"recent\"\n",
        " }\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# screen_name query for actor Salman Khan, whose twitter handle is @BeingSalmanKhan\n",
      "# this because I was curious to see if the number of mentions of Salman Khan could be correlated to his movie release\n",
      "# if I had run this during the month of November, when his movie was released, I could have used actor Shah Rukh Khan \n",
      "# as a control since he has a similar number of twitter followers but no movie release during the month of November\n",
      "# Shah Rukh Khan's twitter handle is @iamsrk\n",
      "\n",
      "from urllib import unquote\n",
      "\n",
      "\n",
      "\n",
      "q = 'BeingSalmanKhan' \n",
      "\n",
      "count = 100\n",
      "\n",
      "since = ''\n",
      "\n",
      "# use since_id to collect subsequent tweets \n",
      "# and prevent duplicate tweet collection\n",
      "since = 671503711135391745\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "\n",
      "search_results = twitter_api.search.tweets(q=q, count=count, since_id=since)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "\n",
      "# Iterate through 5 more batches of results by following the cursor\n",
      "\n",
      "for _ in range(5):\n",
      "    print \"Length of statuses\", len(statuses)\n",
      "    try:\n",
      "        next_results = search_results['search_metadata']['next_results']\n",
      "    except KeyError, e: # No more results when next_results doesn't exist\n",
      "        break\n",
      "        \n",
      "    # Create a dictionary from next_results, which has the following form:\n",
      "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
      "    kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
      "    \n",
      "    search_results = twitter_api.search.tweets(**kwargs)\n",
      "    statuses += search_results['statuses']\n",
      "\n",
      "# Show one sample search result by slicing the list...print json.dumps(statuses[0][\"id\"], indent=1)\n",
      "print json.dumps(statuses[0][\"id\"], indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length of statuses 100\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 400\n",
        "Length of statuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 500\n",
        "672883352718807040"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save tweets to a file\n",
      "\n",
      "filename = \"BeingSalmanKhan-20151204.json\"\n",
      "\n",
      "with open(filename, \"w\") as fp:\n",
      "    json.dump(status_texts, fp)\n",
      "\n",
      "print \"tweets saved to file\"\n",
      "print \"filename is\" , filename\n",
      "print \"you can now use the code in section 2 to analyse these tweets\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tweets saved to file\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I'm not entirely sure what this code does since I already called the twitter API from my first cell\n",
      "# Based on what I've read, I think that first cell authorized me to access the API\n",
      "# and these cells authorize me to exchange information with the API\n",
      "\n",
      "import json\n",
      "from flask import Flask, request\n",
      "import multiprocessing\n",
      "from threading import Timer\n",
      "from IPython.display import IFrame\n",
      "from IPython.display import display\n",
      "from IPython.display import Javascript as JS\n",
      "\n",
      "import twitter\n",
      "from twitter.oauth_dance import parse_oauth_tokens\n",
      "from twitter.oauth import read_token_file, write_token_file\n",
      "\n",
      "# Note: This code is exactly the flow presented in the _AppendixB notebook\n",
      "\n",
      "OAUTH_FILE = \"resources/ch09-twittercookbook/twitter_oauth\"\n",
      "\n",
      "# XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
      "# for these credentials that you'll need to provide in place of these\n",
      "# empty string values that are defined as placeholders.\n",
      "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
      "# on Twitter's OAuth implementation, and ensure that *oauth_callback*\n",
      "# is defined in your application settings as shown next if you are \n",
      "# using Flask in this IPython Notebook.\n",
      "\n",
      "# Define a few variables that will bleed into the lexical scope of a couple of \n",
      "# functions that follow\n",
      "CONSUMER_KEY = '56kWfxP8WyApnJTNCtBJRuO3c'\n",
      "CONSUMER_SECRET = 'c87iGmGG9gogP770Kuscpzx7Bskh5HDdeJBwEjEJyiAj9Niw7I'\n",
      "oauth_callback = 'http://127.0.0.1:5000/oauth_helper'\n",
      "    \n",
      "# Set up a callback handler for when Twitter redirects back to us after the user \n",
      "# authorizes the app\n",
      "\n",
      "webserver = Flask(\"TwitterOAuth\")\n",
      "@webserver.route(\"/oauth_helper\")\n",
      "def oauth_helper():\n",
      "    \n",
      "    oauth_verifier = request.args.get('oauth_verifier')\n",
      "\n",
      "    # Pick back up credentials from ipynb_oauth_dance\n",
      "    oauth_token, oauth_token_secret = read_token_file(OAUTH_FILE)\n",
      "    \n",
      "    _twitter = twitter.Twitter(\n",
      "        auth=twitter.OAuth(\n",
      "            oauth_token, oauth_token_secret, CONSUMER_KEY, CONSUMER_SECRET),\n",
      "        format='', api_version=None)\n",
      "\n",
      "    oauth_token, oauth_token_secret = parse_oauth_tokens(\n",
      "        _twitter.oauth.access_token(oauth_verifier=oauth_verifier))\n",
      "\n",
      "    # This web server only needs to service one request, so shut it down\n",
      "    shutdown_after_request = request.environ.get('werkzeug.server.shutdown')\n",
      "    shutdown_after_request()\n",
      "\n",
      "    # Write out the final credentials that can be picked up after the following\n",
      "    # blocking call to webserver.run().\n",
      "    write_token_file(OAUTH_FILE, oauth_token, oauth_token_secret)\n",
      "    return \"%s %s written to %s\" % (oauth_token, oauth_token_secret, OAUTH_FILE)\n",
      "\n",
      "# To handle Twitter's OAuth 1.0a implementation, we'll just need to implement a \n",
      "# custom \"oauth dance\" and will closely follow the pattern defined in \n",
      "# twitter.oauth_dance.\n",
      "\n",
      "def ipynb_oauth_dance():\n",
      "    \n",
      "    _twitter = twitter.Twitter(\n",
      "        auth=twitter.OAuth('', '', CONSUMER_KEY, CONSUMER_SECRET),\n",
      "        format='', api_version=None)\n",
      "\n",
      "    oauth_token, oauth_token_secret = parse_oauth_tokens(\n",
      "            _twitter.oauth.request_token(oauth_callback=oauth_callback))\n",
      "\n",
      "    # Need to write these interim values out to a file to pick up on the callback \n",
      "    # from Twitter that is handled by the web server in /oauth_helper\n",
      "    write_token_file(OAUTH_FILE, oauth_token, oauth_token_secret)\n",
      "    \n",
      "    oauth_url = ('http://api.twitter.com/oauth/authorize?oauth_token=' + oauth_token)\n",
      "    \n",
      "    # Tap the browser's native capabilities to access the web server through a new \n",
      "    # window to get user authorization\n",
      "    display(JS(\"window.open('%s')\" % oauth_url))\n",
      "\n",
      "# After the webserver.run() blocking call, start the OAuth Dance that will\n",
      "# ultimately cause Twitter to redirect a request back to it. Once that request\n",
      "# is serviced, the web server will shut down and program flow will resume\n",
      "# with the OAUTH_FILE containing the necessary credentials.\n",
      "Timer(1, lambda: ipynb_oauth_dance()).start()\n",
      "\n",
      "webserver.run(host='0.0.0.0')\n",
      "\n",
      "# The values that are read from this file are written out at\n",
      "# the end of /oauth_helper\n",
      "oauth_token, oauth_token_secret = read_token_file(OAUTH_FILE)\n",
      "\n",
      "# These four credentials are what is needed to authorize the application\n",
      "auth = twitter.oauth.OAuth(oauth_token, oauth_token_secret,\n",
      "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
      "    \n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " * Running on http://0.0.0.0:5000/\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "def find_popular_tweets(twitter_api, statuses, retweet_threshold=3):\n",
      "\n",
      "    \n",
      "    return [ status\n",
      "                for status in statuses \n",
      "                    if status['retweet_count'] > retweet_threshold ] \n",
      "    \n",
      "# Sample usage\n",
      "\n",
      "filename = \"BeingSalmanKhan\"\n",
      "\n",
      "twitter_api = oauth_login()\n",
      "search_results = twitter_search(twitter_api, filename, max_results=20)\n",
      "\n",
      "popular_tweets = find_popular_tweets(twitter_api, search_results)\n",
      "\n",
      "for tweet in popular_tweets:\n",
      "    print tweet['text'], tweet['retweet_count']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is how far I got, so far it hasn't worked.  I can't seem to get the oauth to work and then the next script obviously can't run without that."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}